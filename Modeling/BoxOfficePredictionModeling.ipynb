{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the data\n",
    "X_old = pd.read_csv(\"../Data/trainX.csv\")\n",
    "y_old = pd.read_csv(\"../Data/trainY.csv\")\n",
    "target_val_old = pd.read_csv(\"../Data/testX.csv\")\n",
    "\n",
    "X = pd.read_csv(\"../Data/trainX-test.csv\")\n",
    "y = pd.read_csv(\"../Data/trainY-test.csv\")\n",
    "target_val = pd.read_csv(\"../Data/testX-test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['belongs_to_collection',\n",
    " 'has_homepage',\n",
    " 'originally_english',\n",
    " 'topStudio',\n",
    " 'usa_produced',\n",
    " 'released_in_english',\n",
    " 'has_tagline',\n",
    " 'has_keywords',\n",
    " 'topLeadActor',\n",
    " 'topLeadDirector',\n",
    " 'topLeadExecProd',\n",
    " 'topLeadProducer',\n",
    " 'topLeadComposer',\n",
    " 'topLeadDirectorPhoto',\n",
    " 'topLeadEditor',\n",
    " 'log_budget_processed',\n",
    " 'log_genre_rank',\n",
    " 'log_num_genres',\n",
    " 'log_overview_len',\n",
    " 'log_numTopStudios',\n",
    " 'log_num_studios',\n",
    " 'log_num_production_countries',\n",
    " 'log_day_of_week',\n",
    " 'log_year',\n",
    " 'log_month',\n",
    " 'log_week_of_year',\n",
    " 'log_season',\n",
    " 'log_runtime_processed',\n",
    " 'log_num_languages',\n",
    " 'log_title_len',\n",
    " 'log_num_cast',\n",
    " 'log_numTopActors',\n",
    " 'log_numTopDirectors',\n",
    " 'log_numTopExecProd',\n",
    " 'log_numTopProducers',\n",
    " 'log_numTopComposers',\n",
    " 'log_numTopDirectorsPhoto',\n",
    " 'log_numTopEditors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4398.000000\n",
       "mean       16.348816\n",
       "std         1.800308\n",
       "min         0.693147\n",
       "25%        16.012735\n",
       "50%        16.588099\n",
       "75%        17.147715\n",
       "max        19.376192\n",
       "Name: log_budget_processed, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_val_old.log_budget_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['belongs_to_collection', 'has_homepage', 'originally_english',\n",
       "       'topStudio', 'usa_produced', 'released_in_english', 'has_tagline',\n",
       "       'has_keywords', 'topLeadActor', 'topLeadDirector', 'topLeadExecProd',\n",
       "       'topLeadProducer', 'topLeadComposer', 'topLeadDirectorPhoto',\n",
       "       'topLeadEditor', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s',\n",
       "       'log_budget_processed', 'log_genre_rank', 'log_num_genres',\n",
       "       'log_overview_len', 'log_numTopStudios', 'log_num_studios',\n",
       "       'log_studioRank', 'log_num_production_countries', 'log_day_of_week',\n",
       "       'log_year', 'log_month', 'log_week_of_year', 'log_season',\n",
       "       'log_runtime_processed', 'log_num_languages', 'log_title_len',\n",
       "       'log_num_cast', 'log_numTopActors', 'log_actorRanks', 'log_num_crew',\n",
       "       'log_num_male_crew', 'log_num_female_crew', 'log_numTopDirectors',\n",
       "       'log_directorsRank', 'log_numTopExecProd', 'log_execProdRank',\n",
       "       'log_numTopProducers', 'log_producersRank', 'log_numTopComposers',\n",
       "       'log_composersRank', 'log_numTopDirectorsPhoto',\n",
       "       'log_directorsPhotoRank', 'log_numTopEditors', 'log_editorsRank',\n",
       "       'log_budget_to_year_ratio', 'log_runtime_to_year_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['belongs_to_collection', 'has_homepage', 'originally_english',\n",
       "       'topStudio', 'usa_produced', 'released_in_english', 'has_tagline',\n",
       "       'has_keywords', 'topLeadActor', 'topLeadDirector', 'topLeadExecProd',\n",
       "       'topLeadProducer', 'topLeadComposer', 'topLeadDirectorPhoto',\n",
       "       'topLeadEditor', 'log_budget_processed', 'log_genre_rank',\n",
       "       'log_num_genres', 'log_overview_len', 'log_numTopStudios',\n",
       "       'log_num_studios', 'log_num_production_countries', 'log_day_of_week',\n",
       "       'log_year', 'log_month', 'log_week_of_year', 'log_season',\n",
       "       'log_runtime_processed', 'log_num_languages', 'log_title_len',\n",
       "       'log_num_cast', 'log_numTopActors', 'log_numTopDirectors',\n",
       "       'log_numTopExecProd', 'log_numTopProducers', 'log_numTopComposers',\n",
       "       'log_numTopDirectorsPhoto', 'log_numTopEditors', 'log_num_crew',\n",
       "       'log_num_male_crew', 'log_num_female_crew'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_old.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2999.000000\n",
       "mean       16.186409\n",
       "std         1.952961\n",
       "min         0.693147\n",
       "25%        15.424949\n",
       "50%        16.636890\n",
       "75%        17.448669\n",
       "max        20.427616\n",
       "Name: log_budget_processed, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.log_budget_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_new.log_budget_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.log_budget_processed = X_new.log_budget_processed\n",
    "#target_val.log_budget_processed = target_val_new.log_budget_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y['log_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 75/25 stratified split of the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (2399, 57) (2399,)\n",
      "Test set: (600, 57) (600,)\n"
     ]
    }
   ],
   "source": [
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306    11.881962\n",
       "2036    11.775297\n",
       "568     16.692910\n",
       "1896    17.815544\n",
       "2497    14.645964\n",
       "          ...    \n",
       "2108    13.127866\n",
       "2004    16.738203\n",
       "1124    19.828196\n",
       "2401    18.952889\n",
       "905     18.346211\n",
       "Name: log_revenue, Length: 600, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def RMSLE(predict, target):\n",
    "    total = 0 \n",
    "    for k in range(len(predict)):\n",
    "        LPred= np.log1p(predict[k]+1)\n",
    "        LTarg = np.log1p(target[k] + 1)\n",
    "        if not (math.isnan(LPred)) and  not (math.isnan(LTarg)): \n",
    "            total = total + ((LPred-LTarg) **2)\n",
    "        \n",
    "    total = total / len(predict)        \n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_base_model = RandomForestRegressor(random_state = 42)\n",
    "rfr_base_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr_base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.675119754557742"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Accuracy: 96.15 %\n",
      "Test Set Accuracy: 90.86 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "train_errors = abs(rfr_base_model.predict(X_train) - y_train.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "train_mape = 100 * (train_errors / y_train.values)\n",
    "# Calculate and display accuracy\n",
    "train_accuracy = 100 - np.mean(train_mape)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "test_errors = abs(y_pred - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "test_mape = 100 * (test_errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "test_accuracy = 100 - np.mean(test_mape)\n",
    "print('Train Set Accuracy:', round(train_accuracy, 2), '%')\n",
    "print('Test Set Accuracy:', round(test_accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6740143031630637"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSLE(np.expm1(y_pred), np.expm1(y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 25.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7237927304174283\n",
      "{'bootstrap': True, 'max_depth': 25, 'max_features': 0.6, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 25],\n",
    "    'max_features': ['auto', 'log2', .6],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [5, 6, 8],\n",
    "    'n_estimators': [100, 200, 400]\n",
    "}\n",
    "# Create a based model\n",
    "rfr = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "rfr, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, rfr, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-rfr.best_score_))\n",
    "print(rfr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\n",
      "Average Error: 1.1649 degrees.\n",
      "Accuracy = 90.86%.\n",
      "\n",
      "Model after Tuning:\n",
      "Average Error: 1.1632 degrees.\n",
      "Accuracy = 90.46%.\n",
      "Improvement of -0.44%.\n"
     ]
    }
   ],
   "source": [
    "print('Base Model:')\n",
    "base_accuracy = evaluate(rfr_base_model, X_test, y_test.values)\n",
    "print()\n",
    "print('Model after Tuning:')\n",
    "rfr_best_model = rfr.best_estimator_\n",
    "best_accuracy = evaluate(rfr_best_model, X_test, y_test.values)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. log_budget_processed (0.265666)\n",
      "2. log_budget_to_year_ratio (0.245830)\n",
      "3. log_num_male_crew (0.047625)\n",
      "4. log_studioRank (0.039987)\n",
      "5. log_runtime_to_year_ratio (0.030931)\n",
      "6. log_num_studios (0.029925)\n",
      "7. log_actorRanks (0.028847)\n",
      "8. log_num_cast (0.023541)\n",
      "9. topStudio (0.023228)\n",
      "10. log_overview_len (0.020187)\n",
      "11. log_genre_rank (0.019879)\n",
      "12. log_year (0.019290)\n",
      "13. log_runtime_processed (0.018567)\n",
      "14. log_num_crew (0.018030)\n",
      "15. log_week_of_year (0.015308)\n",
      "16. log_numTopStudios (0.015126)\n",
      "17. log_title_len (0.011973)\n",
      "18. log_editorsRank (0.011699)\n",
      "19. log_producersRank (0.009623)\n",
      "20. log_day_of_week (0.009384)\n",
      "21. belongs_to_collection (0.007366)\n",
      "22. log_num_female_crew (0.007215)\n",
      "23. log_month (0.006903)\n",
      "24. log_directorsPhotoRank (0.006420)\n",
      "25. log_num_genres (0.005966)\n",
      "26. log_directorsRank (0.005166)\n",
      "27. log_season (0.005021)\n",
      "28. log_composersRank (0.004501)\n",
      "29. log_num_production_countries (0.004169)\n",
      "30. has_homepage (0.003760)\n",
      "31. 2010s (0.003242)\n",
      "32. has_tagline (0.003153)\n",
      "33. log_numTopActors (0.003116)\n",
      "34. log_execProdRank (0.002898)\n",
      "35. usa_produced (0.002847)\n",
      "36. has_keywords (0.002781)\n",
      "37. log_numTopDirectorsPhoto (0.002556)\n",
      "38. log_numTopComposers (0.002045)\n",
      "39. log_num_languages (0.002018)\n",
      "40. 1990s (0.001962)\n",
      "41. 2000s (0.001865)\n",
      "42. log_numTopProducers (0.001595)\n",
      "43. originally_english (0.001511)\n",
      "44. 1970s (0.001300)\n",
      "45. released_in_english (0.001244)\n",
      "46. log_numTopExecProd (0.000966)\n",
      "47. log_numTopDirectors (0.000797)\n",
      "48. 1980s (0.000611)\n",
      "49. log_numTopEditors (0.000605)\n",
      "50. topLeadActor (0.000450)\n",
      "51. topLeadProducer (0.000264)\n",
      "52. topLeadComposer (0.000253)\n",
      "53. topLeadDirectorPhoto (0.000247)\n",
      "54. topLeadDirector (0.000226)\n",
      "55. topLeadExecProd (0.000191)\n",
      "56. topLeadEditor (0.000108)\n",
      "57. 1960s (0.000014)\n"
     ]
    }
   ],
   "source": [
    "feature_importances = rfr_best_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, X_train.columns[indices[f]], feature_importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from hyperopt import tpe,hp,Trials\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "def objective(params):\n",
    "    est=int(params['n_estimators'])\n",
    "    md=int(params['max_depth'])\n",
    "    msl=int(params['min_samples_leaf'])\n",
    "    mss=int(params['min_samples_split'])\n",
    "    model=RandomForestRegressor(n_estimators=est,max_depth=md,min_samples_leaf=msl,min_samples_split=mss)\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    pred=model.predict(X_test)\n",
    "    score=mean_squared_error(y_test.values,pred)\n",
    "    return score\n",
    "\n",
    "def optimize(trial):\n",
    "    params={'n_estimators':hp.uniform('n_estimators',100,250),\n",
    "           'max_depth':hp.uniform('max_depth',5,100),\n",
    "           'min_samples_leaf':hp.uniform('min_samples_leaf',1,10),\n",
    "           'min_samples_split':hp.uniform('min_samples_split',2,8)}\n",
    "    best=fmin(fn=objective,space=params,algo=tpe.suggest,trials=trial,max_evals=100,rstate=np.random.RandomState(seed))\n",
    "    return best\n",
    "\n",
    "trial=Trials()\n",
    "best=optimize(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_opt=RandomForestRegressor(max_depth =38, min_samples_leaf= 3, min_samples_split = 8, n_estimators = 148)\n",
    "rfr_opt.fit(X_train,y_train.values.ravel())\n",
    "pred_rfr_opt=rfr_opt.predict(X_test)\n",
    "score_rfr_opt=mean_squared_error(y_test.values,pred_rfr_opt)\n",
    "print(np.sqrt(score_rfr_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "train_errors = abs(rfr_opt.predict(X_train) - y_train.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "train_mape = 100 * (train_errors / y_train.values)\n",
    "# Calculate and display accuracy\n",
    "train_accuracy = 100 - np.mean(train_mape)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "test_errors = abs(pred_rfr_opt - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "test_mape = 100 * (test_errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "test_accuracy = 100 - np.mean(test_mape)\n",
    "print('Train Set Accuracy:', round(train_accuracy, 2), '%')\n",
    "print('Test Set Accuracy:', round(test_accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "et_base_model = ExtraTreesRegressor()\n",
    "et_base_model.fit(X_train, y_train.values.ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = et_base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test.values)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_model = ExtraTreesRegressor()\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "et_model, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, et_model, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-et_model.best_score_))\n",
    "print(et_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ExtraTreesRegressor()\n",
    "base_model.fit(X_train, y_train.values.ravel())\n",
    "base_accuracy = evaluate(base_model, X_test, y_test.values)\n",
    "\n",
    "et_best_model = et_model.best_estimator_\n",
    "best_accuracy = evaluate(et_best_model, X_test, y_test.values)\n",
    "\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance\n",
    "Average Error: 2.8057 degrees.\n",
    "Accuracy = 73.40%.\n",
    "Model Performance\n",
    "Average Error: 2.5961 degrees.\n",
    "Accuracy = 74.66%.\n",
    "Improvement of 1.71%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = et_best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = et_best_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, X_train.columns[indices[f]], feature_importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "def objective(params):\n",
    "    est=int(params['n_estimators'])\n",
    "    md=int(params['max_depth'])\n",
    "    msl=int(params['min_samples_leaf'])\n",
    "    mss=int(params['min_samples_split'])\n",
    "    model=ExtraTreesRegressor(n_estimators=est,max_depth=md,min_samples_leaf=msl,min_samples_split=mss)\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    pred=model.predict(X_test)\n",
    "    score=mean_squared_error(y_test.values,pred)\n",
    "    return score\n",
    "\n",
    "def optimize(trial):\n",
    "    params={'n_estimators':hp.uniform('n_estimators',100,250),\n",
    "           'max_depth':hp.uniform('max_depth',5,100),\n",
    "           'min_samples_leaf':hp.uniform('min_samples_leaf',1,10),\n",
    "           'min_samples_split':hp.uniform('min_samples_split',2,8)}\n",
    "    best=fmin(fn=objective,space=params,algo=tpe.suggest,trials=trial,max_evals=100,rstate=np.random.RandomState(seed))\n",
    "    return best\n",
    "\n",
    "trial=Trials()\n",
    "best=optimize(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_opt=ExtraTreesRegressor(max_depth =97, min_samples_leaf= 5, min_samples_split = 2, n_estimators = 197)\n",
    "et_opt.fit(X_train,y_train.values.ravel())\n",
    "pred_et_opt=rfr_opt.predict(X_test)\n",
    "score_et_opt=mean_squared_error(y_test.values,pred_rfr_opt)\n",
    "print(np.sqrt(score_rfr_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "train_errors = abs(et_opt.predict(X_train) - y_train.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "train_mape = 100 * (train_errors / y_train.values)\n",
    "# Calculate and display accuracy\n",
    "train_accuracy = 100 - np.mean(train_mape)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "test_errors = abs(pred_et_opt - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "test_mape = 100 * (test_errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "test_accuracy = 100 - np.mean(test_mape)\n",
    "print('Train Set Accuracy:', round(train_accuracy, 2), '%')\n",
    "print('Test Set Accuracy:', round(test_accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSLE(np.expm1(pred_et_opt), np.expm1(y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base_model = xgb.XGBRegressor()\n",
    "xgb_base_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "train_errors = abs(xgb_base_model.predict(X_train) - y_train.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "train_mape = 100 * (train_errors / y_train.values)\n",
    "# Calculate and display accuracy\n",
    "train_accuracy = 100 - np.mean(train_mape)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "test_errors = abs(y_pred - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "test_mape = 100 * (test_errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "test_accuracy = 100 - np.mean(test_mape)\n",
    "print('Train Set Accuracy:', round(train_accuracy, 2), '%')\n",
    "print('Test Set Accuracy:', round(test_accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'colsample_bytree': [1.0, 1.1, 1.5],\n",
    "    'max_depth': [1, 5, 100],\n",
    "    'reg_alpha': [1.2, 1.3, 1.4],\n",
    "    'reg_lambda': [ 1.2, 1.3],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, xgb_model, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-xgb_model.best_score_))\n",
    "print(xgb_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Base Model:')\n",
    "base_accuracy = evaluate(xgb_base_model, X_test, y_test.values)\n",
    "print()\n",
    "print('Model after Tuning:')\n",
    "xgb_best_model = xgb_model.best_estimator_\n",
    "best_accuracy = evaluate(xgb_best_model, X_test, y_test.values)\n",
    "\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = xgb_best_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, X_train.columns[indices[f]], feature_importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# evaluate the model\n",
    "lgbm_base_model = LGBMRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "lgbm_base_model = LGBMRegressor()\n",
    "lgbm_base_model.fit(X_train, y_train)\n",
    "# make a single prediction\n",
    "row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
    "yhat = lgbm_base_model.predict(X_test)\n",
    "print('Prediction: %.3f' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test,yhat)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(yhat - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8],\n",
    "    'max_depth': [1, 2, 5],\n",
    "    'reg_alpha': [1.0, 1.1, 1.2],\n",
    "    'reg_lambda': [1.2, 1.3],\n",
    "    'subsample': [0.3,0.35, 0.4]\n",
    "\n",
    "}\n",
    "# Create a based model\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, lgbm, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-lgbm.best_score_))\n",
    "print(lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_base_model = LGBMRegressor()\n",
    "lgbm_base_model.fit(X_train, y_train.values.ravel())\n",
    "base_accuracy = evaluate(lgbm_base_model, X_test, y_test.values)\n",
    "\n",
    "lgbm_best_model = lgbm.best_estimator_\n",
    "best_accuracy = evaluate(lgbm_best_model, X_test, y_test.values)\n",
    "\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = lgbm_best_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, X_train.columns[indices[f]], feature_importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['id','revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=et_opt.predict(target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3001, len(target_val) + 3001):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results['id'] = range(3001, len(target_val) + 3001)\n",
    "#results['revenue'] = np.expm1(preds)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.to_csv(\"ET_baseline2-85p.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
