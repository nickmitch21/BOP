{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the data\n",
    "X = pd.read_csv(\"../Data/trainX.csv\")\n",
    "y = pd.read_csv(\"../Data/trainY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 75/25 stratified split of the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (2249, 41) (2249, 1)\n",
      "Test set: (750, 41) (750, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_base_model = RandomForestRegressor(random_state = 42)\n",
    "rfr_base_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr_base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.148237538429347"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.19 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.254025478827444\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rfr = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "rfr, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, rfr, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-rfr.best_score_))\n",
    "print(rfr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\n",
      "Average Error: 2.8428 degrees.\n",
      "Accuracy = 73.19%.\n",
      "\n",
      "Model after Tuning:\n",
      "Average Error: 2.6522 degrees.\n",
      "Accuracy = 74.31%.\n",
      "Improvement of 1.54%.\n"
     ]
    }
   ],
   "source": [
    "print('Base Model:')\n",
    "base_accuracy = evaluate(rfr_base_model, X_test, y_test.values)\n",
    "print()\n",
    "print('Model after Tuning:')\n",
    "rfr_best_model = rfr.best_estimator_\n",
    "best_accuracy = evaluate(rfr_best_model, X_test, y_test.values)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model:\n",
    "Model Performance\n",
    "Average Error: 2.8720 degrees.\n",
    "Accuracy = 73.01%.\n",
    "\n",
    "Model after Tuning:\n",
    "Model Performance\n",
    "Average Error: 2.6519 degrees.\n",
    "Accuracy = 74.33%.\n",
    "Improvement of 1.81%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "et_base_model = ExtraTreesRegressor()\n",
    "et_base_model.fit(X_train, y_train.values.ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = et_base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.81\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test.values)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.38 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3428684167217635\n",
      "{'bootstrap': True, 'max_depth': 110, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "et_model = ExtraTreesRegressor()\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "et_model, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, et_model, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-et_model.best_score_))\n",
    "print(et_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 2.8068 degrees.\n",
      "Accuracy = 73.39%.\n",
      "Average Error: 2.5956 degrees.\n",
      "Accuracy = 74.66%.\n",
      "Improvement of 1.73%.\n"
     ]
    }
   ],
   "source": [
    "base_model = ExtraTreesRegressor()\n",
    "base_model.fit(X_train, y_train.values.ravel())\n",
    "base_accuracy = evaluate(base_model, X_test, y_test.values)\n",
    "\n",
    "et_best_model = et_model.best_estimator_\n",
    "best_accuracy = evaluate(et_best_model, X_test, y_test.values)\n",
    "\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance\n",
    "Average Error: 2.8057 degrees.\n",
    "Accuracy = 73.40%.\n",
    "Model Performance\n",
    "Average Error: 2.5961 degrees.\n",
    "Accuracy = 74.66%.\n",
    "Improvement of 1.71%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_base_model = xgb.XGBRegressor()\n",
    "xgb_base_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2080 tasks      | elapsed:  7.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1575986325294387\n",
      "{'colsample_bytree': 1.0, 'max_depth': 1, 'n_estimators': 200, 'reg_alpha': 1.3, 'reg_lambda': 1.2, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2430 out of 2430 | elapsed:  7.8min finished\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'colsample_bytree': [1.0, 1.1, 1.5],\n",
    "    'max_depth': [1, 5, 100],\n",
    "    'reg_alpha': [1.2, 1.3, 1.4],\n",
    "    'reg_lambda': [ 1.2, 1.3],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, xgb_model, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-xgb_model.best_score_))\n",
    "print(xgb_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\n",
      "Average Error: 2.9210 degrees.\n",
      "Accuracy = 72.58%.\n",
      "\n",
      "Model after Tuning:\n",
      "Average Error: 2.8031 degrees.\n",
      "Accuracy = 73.34%.\n",
      "Improvement of 1.04%.\n"
     ]
    }
   ],
   "source": [
    "print('Base Model:')\n",
    "base_accuracy = evaluate(xgb_base_model, X_test, y_test.values)\n",
    "print()\n",
    "print('Model after Tuning:')\n",
    "xgb_best_model = xgb_model.best_estimator_\n",
    "best_accuracy = evaluate(xgb_best_model, X_test, y_test.values)\n",
    "\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -1.416 (0.116)\n",
      "Prediction: 13.543\n"
     ]
    }
   ],
   "source": [
    "# lightgbm for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# evaluate the model\n",
    "lgbm_base_model = LGBMRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "lgbm_base_model = LGBMRegressor()\n",
    "lgbm_base_model.fit(X_train, y_train)\n",
    "# make a single prediction\n",
    "row = [[2.02220122, 0.31563495, 0.82797464, -0.30620401, 0.16003707, -1.44411381, 0.87616892, -0.50446586, 0.23009474, 0.76201118]]\n",
    "yhat = lgbm_base_model.predict(X_test)\n",
    "print('Prediction: %.3f' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1904772793411964"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test,yhat)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.92 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(yhat - y_test.values)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test.values)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1272 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2002 tasks      | elapsed:   56.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.127612202661131\n",
      "{'colsample_bytree': 0.7, 'max_depth': 5, 'n_estimators': 100, 'reg_alpha': 1.1, 'reg_lambda': 1.2, 'subsample': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8],\n",
    "    'max_depth': [1, 2, 5],\n",
    "    'reg_alpha': [1.0, 1.1, 1.2],\n",
    "    'reg_lambda': [1.2, 1.3],\n",
    "    'subsample': [0.3,0.35, 0.4]\n",
    "\n",
    "}\n",
    "# Create a based model\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm, pred = algorithm_pipeline(X_train, X_test, y_train.values.ravel(), y_test.values, lgbm, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-lgbm.best_score_))\n",
    "print(lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 2.8664 degrees.\n",
      "Accuracy = 72.92%.\n",
      "Average Error: 2.8347 degrees.\n",
      "Accuracy = 73.13%.\n",
      "Improvement of 0.29%.\n"
     ]
    }
   ],
   "source": [
    "lgbm_base_model = LGBMRegressor()\n",
    "lgbm_base_model.fit(X_train, y_train.values.ravel())\n",
    "base_accuracy = evaluate(lgbm_base_model, X_test, y_test.values)\n",
    "\n",
    "lgbm_best_model = lgbm.best_estimator_\n",
    "best_accuracy = evaluate(lgbm_best_model, X_test, y_test.values)\n",
    "\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (best_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance\n",
    "Average Error: 2.8664 degrees.\n",
    "Accuracy = 72.92%.\n",
    "Model Performance\n",
    "Average Error: 2.8347 degrees.\n",
    "Accuracy = 73.13%.\n",
    "Improvement of 0.29%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
